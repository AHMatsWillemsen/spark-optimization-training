{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download generic purpose datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ds-with-spark.zip\n",
      "  inflating: ted_main.csv            \n",
      "  inflating: __MACOSX/._ted_main.csv  \n",
      "  inflating: ted_transcripts.csv     \n",
      "  inflating: __MACOSX/._ted_transcripts.csv  \n",
      "  inflating: used_cars.csv           \n",
      "  inflating: __MACOSX/._used_cars.csv  \n",
      "  inflating: aac_intakes_outcomes.csv  \n",
      "  inflating: __MACOSX/._aac_intakes_outcomes.csv  \n",
      "  inflating: aac_intakes.csv         \n",
      "  inflating: __MACOSX/._aac_intakes.csv  \n",
      "  inflating: aac_outcomes.csv        \n",
      "  inflating: __MACOSX/._aac_outcomes.csv  \n",
      "  inflating: airlines.parquet        \n",
      "  inflating: __MACOSX/._airlines.parquet  \n",
      "  inflating: band1.txt               \n",
      "  inflating: band2.txt               \n",
      "  inflating: chicagoAllWeather.csv   \n",
      "  inflating: __MACOSX/._chicagoAllWeather.csv  \n",
      "  inflating: chicagoCensus.csv       \n",
      "  inflating: __MACOSX/._chicagoCensus.csv  \n",
      "  inflating: chicagoCrimes10k.csv    \n",
      "  inflating: __MACOSX/._chicagoCrimes10k.csv  \n",
      "  inflating: complete-day.parquet    \n",
      "  inflating: __MACOSX/._complete-day.parquet  \n",
      "  inflating: heroes.csv              \n",
      "  inflating: __MACOSX/._heroes.csv   \n",
      "   creating: meetup.json/\n",
      "  inflating: __MACOSX/._meetup.json  \n",
      "  inflating: meetup.json/0           \n",
      "  inflating: NASA_access_log_Jul95   \n",
      "  inflating: NASA_access_log_Jul95.txt  \n",
      "  inflating: noshowappointments.csv  \n",
      "  inflating: __MACOSX/._noshowappointments.csv  \n",
      "  inflating: nyc-taxi-2m.csv.gz      \n",
      "  inflating: __MACOSX/._nyc-taxi-2m.csv.gz  \n",
      "  inflating: oefendata_winkel_transacties.csv  \n",
      "  inflating: __MACOSX/._oefendata_winkel_transacties.csv  \n",
      "  inflating: results-20190827-215633.csv  \n",
      "  inflating: __MACOSX/._results-20190827-215633.csv  \n",
      "  inflating: results-20190827-215908.csv  \n",
      "  inflating: __MACOSX/._results-20190827-215908.csv  \n",
      "  inflating: sample_movielens_ratings.txt  \n",
      "  inflating: scores.txt              \n",
      "  inflating: us-500.csv              \n",
      "  inflating: __MACOSX/._us-500.csv   \n",
      "  inflating: weather.csv             \n",
      "  inflating: __MACOSX/._weather.csv  \n",
      "  inflating: words                   \n",
      "  inflating: __MACOSX/._words        \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wget -P data/ds-spark -q https://storage.googleapis.com/academy-data/ds-with-spark.zip\n",
    "cd data/ds-spark; unzip ds-with-spark.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download weather dataset format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget -q https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/ghcn-daily-by_year-format.rtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: striprtf in /usr/local/lib/python3.7/dist-packages (0.0.11)\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "pip3 install striprtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following information serves as a definition of each field in one line of data covering one station-day. Each field described below is separated by a comma ( , ) and follows the order\n",
      "presented in this document.\n",
      "\n",
      "ID = 11 character station identification code\n",
      "YEAR/MONTH/DAY = 8 character date in YYYYMMDD format (e.g. 19860529 = May 29, 1986)\n",
      "ELEMENT = 4 character indicator of element type \n",
      "DATA VALUE = 5 character data value for ELEMENT \n",
      "M-FLAG = 1 character Measurement Flag \n",
      "Q-FLAG = 1 character Quality Flag \n",
      "S-FLAG = 1 character Source Flag \n",
      "OBS-TIME = 4-character time of observation in hour-minute format (i.e. 0700 =7:00 am)\n",
      "\n",
      "See section III of the GHCN-Daily readme.txt file for an explanation of ELEMENT codes and their units as well as the M-FLAG, Q-FLAGS and S-FLAGS.\n",
      "\n",
      "The OBS-TIME field is populated with the observation times contained in NOAA/NCDCâ€™s Multinetwork Metadata System (MMS).  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from striprtf.striprtf import rtf_to_text\n",
    "\n",
    "with open('ghcn-daily-by_year-format.rtf', 'r') as file:\n",
    "    data = file.read().replace('\\n', '')\n",
    "\n",
    "text = rtf_to_text(data) \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and show data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 2017.\n",
      "Finished 2018.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "START=2017\n",
    "END=2018\n",
    "for ((i=$START;i<=END;i++)); do \n",
    "    wget -P data/weather -q https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/$i.csv.gz\n",
    "    echo \"Finished $i.\"\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(\"pyspark-1\").\\\n",
    "        master(\"spark://spark-master:7077\").\\\n",
    "        config(\"spark.executor.enabled\", \"true\").\\\n",
    "        config(\"spark.eventLog.dir\", \"/opt/workspace/history\").\\\n",
    "        getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv(\"data/weather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+----+----+----+---+---+----+\n",
      "|        _c0|     _c1| _c2| _c3| _c4|_c5|_c6| _c7|\n",
      "+-----------+--------+----+----+----+---+---+----+\n",
      "|ASN00061390|20170101|PRCP|   0|null|  L|  a|null|\n",
      "|ASN00065036|20170101|DAPR|   2|null|  L|  a|null|\n",
      "|ASN00065036|20170101|MDPR|  10|null|  L|  a|null|\n",
      "|ASN00073141|20170101|TMAX| 223|null|  S|  a|null|\n",
      "|CA001037090|20170101|WSFG|1190|null|  X|  C|null|\n",
      "|CA001039035|20170101|SNWD|   0|null|  I|  C|null|\n",
      "|CA00109E7R6|20170101|SNWD|   0|null|  I|  C|null|\n",
      "|CA001106CL2|20170101|TMAX|   0|null|  N|  C|null|\n",
      "|CA001106CL2|20170101|TMIN|   0|null|  N|  C|null|\n",
      "|CA001106CL2|20170101|SNOW|   0|null|  I|  C|null|\n",
      "+-----------+--------+----+----+----+---+---+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.where('_c5 is not null').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID',\n",
       " 'YYYYMMDD',\n",
       " 'ELEMENT',\n",
       " 'DATA_VALUE',\n",
       " 'M-FLAG',\n",
       " 'Q-FLAG',\n",
       " 'S-FLAG',\n",
       " 'OBS-TIME']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = \"ID, YYYYMMDD, ELEMENT, DATA_VALUE, M-FLAG, Q-FLAG, S-FLAG, OBS-TIME\".split(', ')\n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0', '_c1', '_c2', '_c3', '_c4', '_c5', '_c6', '_c7']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " data.schema.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- YYYYMMDD: string (nullable = true)\n",
      " |-- ELEMENT: string (nullable = true)\n",
      " |-- DATA_VALUE: string (nullable = true)\n",
      " |-- M-FLAG: string (nullable = true)\n",
      " |-- Q-FLAG: string (nullable = true)\n",
      " |-- S-FLAG: string (nullable = true)\n",
      " |-- OBS-TIME: string (nullable = true)\n",
      "\n",
      "+-----------+--------+-------+----------+------+------+------+--------+\n",
      "|         ID|YYYYMMDD|ELEMENT|DATA_VALUE|M-FLAG|Q-FLAG|S-FLAG|OBS-TIME|\n",
      "+-----------+--------+-------+----------+------+------+------+--------+\n",
      "|AE000041196|20170101|   TMIN|       163|  null|  null|     S|    null|\n",
      "|AE000041196|20170101|   TAVG|       217|     H|  null|     S|    null|\n",
      "|AEM00041194|20170101|   PRCP|         0|  null|  null|     S|    null|\n",
      "|AEM00041194|20170101|   TAVG|       223|     H|  null|     S|    null|\n",
      "|AEM00041218|20170101|   TMIN|       137|  null|  null|     S|    null|\n",
      "|AEM00041218|20170101|   TAVG|       202|     H|  null|     S|    null|\n",
      "|AEM00041217|20170101|   TMIN|       159|  null|  null|     S|    null|\n",
      "|AEM00041217|20170101|   TAVG|       206|     H|  null|     S|    null|\n",
      "|AFM00040938|20170101|   TAVG|       154|     H|  null|     S|    null|\n",
      "|AFM00040948|20170101|   TAVG|        69|     H|  null|     S|    null|\n",
      "+-----------+--------+-------+----------+------+------+------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "oldColumns = data.schema.names\n",
    "df = reduce(lambda data, idx: data.withColumnRenamed(oldColumns[idx], header[idx]), range(len(oldColumns)), data)\n",
    "df.printSchema()\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
